{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyun/anaconda3/envs/ai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from future.utils.surrogateescape import encoded\n",
    "\n",
    "from Models.DT import *\n",
    "from utils.utils import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from Models.AutoEncoder import AE_trainDataset, AE_validDataset, AE_Dataset\n",
    "from utils.utils import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import experiments.autoencoder_experiment_ver4_1 as AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec9d7cb8a6da03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e572b19eb84eb8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    'Gender',\n",
    "    'Zipcode',\n",
    "    'Day',\n",
    "    'Card Brand',\n",
    "    'Card Type',\n",
    "    'Has Chip',\n",
    "    'Whether Security Chip is Used',\n",
    "    'Error Message',\n",
    "    'WeekDay',\n",
    "    'Credit Signal',\n",
    "    'PIN Change',\n",
    "    'Security Level'\n",
    "]\n",
    "num_features = [\n",
    "    'Current Age',\n",
    "    'Retirement Age',\n",
    "    'Per Capita Income - Zipcode',\n",
    "    'Yearly Income',\n",
    "    'Total Debt',\n",
    "    'Credit Score',\n",
    "    'Valid Month',\n",
    "    'Credit Limit',\n",
    "    'Since Open Month',\n",
    "    'Year PIN last Changed',\n",
    "    'Amount',\n",
    "    'Credit Util',\n",
    "    'Years Changed PIN',\n",
    "    'Security Score'\n",
    "]\n",
    "discarded = [\n",
    "    'User',\n",
    "    'Birth Year',\n",
    "    'Birth Month',\n",
    "    'Year',\n",
    "    'Month',\n",
    "    'Merchandise Code',\n",
    "    'Card',\n",
    "    'Card Number',\n",
    "    'Expires',\n",
    "    'Acct Open Date',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b7b1d007c9f06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_401660/900160243.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder(\n",
      "  (cat_embeddings): ModuleList(\n",
      "    (0-11): 12 x Embedding(100, 5)\n",
      "  )\n",
      "  (fc_cat): Linear(in_features=74, out_features=64, bias=True)\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=31, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=31, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=74, bias=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_path = 'experiments/AutoEncoder4_1/AE4_1_dim31_batch256_lr0.000100_l10.000003.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = AE.AutoEncoder(encoding_dim=31, cat_features=cat_features, num_features=num_features, num_classes=1)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3276eb6da74c20e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSITION\n",
      "IQR\n",
      "SPLIT\n",
      "DISCARD\n",
      "SCALE\n",
      "ENCODE\n",
      "TARGET\n",
      "TRAIN CAT/NUM\n",
      "VALID CAT/NUM\n",
      "RETURN\n"
     ]
    }
   ],
   "source": [
    "(train_cat_X, train_num_X, train_y), (valid_cat_X, valid_num_X, valid_y), label_encoders, _ = dt_process_data(\n",
    "    './Data/[24-2 DS_Project2] Data.csv',\n",
    "    cat_features,\n",
    "    num_features,\n",
    "    discarded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55ac4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42, sampling_strategy=0.5)\n",
    "train_X_resampled, train_y_resampled = smote.fit_resample(\n",
    "    pd.concat([train_cat_X, train_num_X], axis=1), train_y['Is Fraud?']\n",
    ")\n",
    "# Resampled 데이터를 나누기\n",
    "train_cat_X_resampled = train_X_resampled[cat_features]\n",
    "train_num_X_resampled = train_X_resampled[num_features]\n",
    "train_y_resampled = pd.DataFrame(train_y_resampled, columns=['Is Fraud?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ddef66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Is Fraud?\n",
      "0.0    733455\n",
      "1.0       897\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: Is Fraud?\n",
      "0.0    733455\n",
      "1.0    366727\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Before SMOTE:\", train_y['Is Fraud?'].value_counts())\n",
    "print(\"After SMOTE:\", train_y_resampled['Is Fraud?'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bee02bb3a6650a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T16:33:21.401670Z",
     "start_time": "2024-11-30T16:33:21.397116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (cat_embeddings): ModuleList(\n",
       "    (0-11): 12 x Embedding(100, 5)\n",
       "  )\n",
       "  (fc_cat): Linear(in_features=74, out_features=64, bias=True)\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=31, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=31, out_features=64, bias=True)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=64, out_features=74, bias=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c008d24f39576e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T16:33:22.012135Z",
     "start_time": "2024-11-30T16:33:21.878688Z"
    }
   },
   "outputs": [],
   "source": [
    "train_embeddings = model.get_embedding(\n",
    "    torch.tensor(train_cat_X_resampled.values, dtype=torch.long).to(device),\n",
    "    torch.tensor(train_num_X_resampled.values, dtype=torch.float).to(device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e619497a1beb5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T16:33:22.476906Z",
     "start_time": "2024-11-30T16:33:22.451095Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_embeddings = model.get_embedding(\n",
    "    torch.tensor(valid_cat_X.values, dtype=torch.long).to(device),\n",
    "    torch.tensor(valid_num_X.values, dtype=torch.float).to(device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b74afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = train_embeddings.cpu().detach().numpy()\n",
    "valid_embeddings = valid_embeddings.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b144bfed44245d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T16:39:25.698222Z",
     "start_time": "2024-11-30T16:33:22.900780Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=300,          # 트리 개수 더욱 증가\n",
    "    max_depth=15,              # 더 깊은 트리 허용\n",
    "    min_samples_leaf=1,        # 리프 노드 최소 샘플 수 더 감소\n",
    "    min_samples_split=3,       # 분할 기준 완화\n",
    "    class_weight={0: 1, 1: 12},  # 사기 클래스에 더 높은 가중치 부여\n",
    "    max_features='sqrt',       \n",
    "    bootstrap=True,\n",
    "    oob_score=True,           # Out-of-bag 점수 확인\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf5756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyun/anaconda3/envs/ai/lib/python3.12/site-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[132890 116832]\n",
      " [   143    215]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.53      0.69    249722\n",
      "         1.0       0.00      0.60      0.00       358\n",
      "\n",
      "    accuracy                           0.53    250080\n",
      "   macro avg       0.50      0.57      0.35    250080\n",
      "weighted avg       1.00      0.53      0.69    250080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_classifier.fit(train_embeddings, train_y_resampled)\n",
    "y_pred = rf_classifier.predict(valid_embeddings)\n",
    "conf_matrix = confusion_matrix(valid_y, y_pred)\n",
    "class_report = classification_report(valid_y, y_pred)\n",
    "print(conf_matrix)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c042c4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest 결과:\n",
      "\n",
      "혼동 행렬:\n",
      "[[249022    700]\n",
      " [   358      0]]\n",
      "\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    249722\n",
      "         1.0       0.00      0.00      0.00       358\n",
      "\n",
      "    accuracy                           1.00    250080\n",
      "   macro avg       0.50      0.50      0.50    250080\n",
      "weighted avg       1.00      1.00      1.00    250080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Isolation Forest를 사용한 이상 탐지\n",
    "# Isolation Forest 파라미터 조정\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=500,          # 트리 개수 증가\n",
    "    max_samples=256,           # 명시적인 샘플 크기 지정\n",
    "    contamination=0.002,       # 실제 사기 비율에 더 가깝게 조정\n",
    "    max_features=0.8,          # 특성 샘플링 비율 지정\n",
    "    bootstrap=True,            # 부트스트랩 샘플링 활성화\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 학습 데이터로 모델 학습\n",
    "iso_forest.fit(train_embeddings)\n",
    "\n",
    "# 예측 수행 (1: 정상, -1: 이상치)\n",
    "iso_pred = iso_forest.predict(valid_embeddings)\n",
    "\n",
    "# -1을 1로, 1을 0으로 변환하여 fraud/non-fraud 레이블로 매핑\n",
    "iso_pred_mapped = np.where(iso_pred == -1, 1, 0)\n",
    "\n",
    "# 성능 평가\n",
    "iso_conf_matrix = confusion_matrix(valid_y, iso_pred_mapped)\n",
    "iso_class_report = classification_report(valid_y, iso_pred_mapped)\n",
    "\n",
    "print(\"Isolation Forest 결과:\")\n",
    "print(\"\\n혼동 행렬:\")\n",
    "print(iso_conf_matrix)\n",
    "print(\"\\n분류 보고서:\")\n",
    "print(iso_class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6371f089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
