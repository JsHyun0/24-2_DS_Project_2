{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyun/anaconda3/envs/ai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from future.utils.surrogateescape import encoded\n",
    "\n",
    "from Models.DT import *\n",
    "from utils.utils import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from Models.AutoEncoder import AE_trainDataset, AE_validDataset, AE_Dataset\n",
    "from utils.utils import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import experiments.autoencoder_experiment_ver4_1 as AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec9d7cb8a6da03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "215f18d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"encoding_dim\": 31,\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 1e-4,  # lr을 trial 파라미터로 변경\n",
    "    \"epochs\": 200,\n",
    "    \"threshold_percentile\": 95,\n",
    "    \"l1_lambda\": 1e-6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e572b19eb84eb8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    'Gender',\n",
    "    'Zipcode',\n",
    "    'Day',\n",
    "    'Card Brand',\n",
    "    'Card Type',\n",
    "    'Has Chip',\n",
    "    'Whether Security Chip is Used',\n",
    "    'Error Message',\n",
    "    'WeekDay',\n",
    "    'Credit Signal',\n",
    "    'PIN Change',\n",
    "    'Security Level'\n",
    "]\n",
    "num_features = [\n",
    "    'Current Age',\n",
    "    'Retirement Age',\n",
    "    'Per Capita Income - Zipcode',\n",
    "    'Yearly Income',\n",
    "    'Total Debt',\n",
    "    'Credit Score',\n",
    "    'Valid Month',\n",
    "    'Credit Limit',\n",
    "    'Since Open Month',\n",
    "    'Year PIN last Changed',\n",
    "    'Amount',\n",
    "    'Credit Util',\n",
    "    'Years Changed PIN',\n",
    "    'Security Score'\n",
    "]\n",
    "discarded = [\n",
    "    'User',\n",
    "    'Birth Year',\n",
    "    'Birth Month',\n",
    "    'Year',\n",
    "    'Month',\n",
    "    'Merchandise Code',\n",
    "    'Card',\n",
    "    'Card Number',\n",
    "    'Expires',\n",
    "    'Acct Open Date',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64b7b1d007c9f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'experiments/AutoEncoder4_1/AE4_1_dim31_batch256_lr0.000100_l10.000003.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = AE.AutoEncoder(encoding_dim=31, cat_features=cat_features, num_features=num_features, num_classes=1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3276eb6da74c20e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSITION\n",
      "IQR\n",
      "SPLIT\n",
      "DISCARD\n",
      "SCALE\n",
      "ENCODE\n",
      "TARGET\n",
      "TRAIN CAT/NUM\n",
      "VALID CAT/NUM\n",
      "RETURN\n"
     ]
    }
   ],
   "source": [
    "(train_cat_X, train_num_X, train_y), (valid_cat_X, valid_num_X, valid_y), label_encoders, _ = dt_process_data(\n",
    "    './Data/[24-2 DS_Project2] Data.csv',\n",
    "    cat_features,\n",
    "    num_features,\n",
    "    discarded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c55ac4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42, sampling_strategy=0.4)\n",
    "train_X_resampled, train_y_resampled = smote.fit_resample(\n",
    "    pd.concat([train_cat_X, train_num_X], axis=1), train_y['Is Fraud?']\n",
    ")\n",
    "# Resampled 데이터를 나누기\n",
    "train_cat_X_resampled = train_X_resampled[cat_features]\n",
    "train_num_X_resampled = train_X_resampled[num_features]\n",
    "train_y_resampled = pd.DataFrame(train_y_resampled, columns=['Is Fraud?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91c1b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AE_validDataset(train_cat_X_resampled, train_num_X_resampled, train_y_resampled, device)\n",
    "valid_dataset = AE_validDataset(valid_cat_X, valid_num_X, valid_y, device)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4ddef66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Is Fraud?\n",
      "0.0    733455\n",
      "1.0       897\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: Is Fraud?\n",
      "0.0    733455\n",
      "1.0    293382\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Before SMOTE:\", train_y['Is Fraud?'].value_counts())\n",
    "print(\"After SMOTE:\", train_y_resampled['Is Fraud?'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bee02bb3a6650a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T16:33:21.401670Z",
     "start_time": "2024-11-30T16:33:21.397116Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if isinstance(param, nn.Linear):\n",
    "        nn.init.kaiming_normal_(param.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if param.bias is not None:\n",
    "            nn.init.zeros_(param.bias)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "criterion = nn.MSELoss()\n",
    "best_loss = float('inf')\n",
    "l1_lambda = config[\"l1_lambda\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "369c90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55878efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [03:55<1:34:07, 29.42s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 총 손실 = MSE 손실 + L1 정규화\u001b[39;00m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m mse_loss \u001b[38;5;241m+\u001b[39m l1_lambda \u001b[38;5;241m*\u001b[39m l1_reg\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(config[\"epochs\"])):\n",
    "    # 학습 단계\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # tqdm으로 배치 진행률 표시\n",
    "    for cat_features, num_features, labels in tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False):\n",
    "        optimizer.zero_grad()\n",
    "        y_hat, y = model(cat_features, num_features)\n",
    "        \n",
    "        # MSE 손실 계산\n",
    "        mse_loss = criterion(y_hat, y)\n",
    "        \n",
    "        # L1 정규화 계산\n",
    "        l1_reg = torch.tensor(0., requires_grad=True).to(device)\n",
    "        for param in model.parameters():\n",
    "            l1_reg = l1_reg + torch.norm(param, 1)\n",
    "        \n",
    "        # 총 손실 = MSE 손실 + L1 정규화\n",
    "        loss = mse_loss + l1_lambda * l1_reg\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # 평균 train_loss 계산\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    # 검증 단계 수정 (매 에포크마다 검증 수행)\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    reconstruction_errors = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for cat_features, num_features, labels in valid_loader:\n",
    "            y_hat, y = model(cat_features, num_features)\n",
    "            batch_loss = criterion(y_hat, y)\n",
    "            valid_loss += batch_loss.item()\n",
    "            \n",
    "            # 재구성 오차 저장\n",
    "            errors = torch.mean((y_hat - y) ** 2, dim=1)\n",
    "            reconstruction_errors.extend(errors.cpu().numpy())\n",
    "        \n",
    "        valid_loss /= len(valid_loader)\n",
    "        \n",
    "        # Early Stopping 로직\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            # 모델의 state dict를 저장\n",
    "            model_state_dict = model.state_dict()\n",
    "            # 모델 state dict를 파일로 저장\n",
    "            torch.save(model_state_dict, 'best_model_state_4_1.pth')\n",
    "            # 나중에 필요할 때 불러오기\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f201e2aa",
   "metadata": {},
   "source": [
    "## Tree 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_state_4_1.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c008d24f39576e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T16:33:22.012135Z",
     "start_time": "2024-11-30T16:33:21.878688Z"
    }
   },
   "outputs": [],
   "source": [
    "train_embeddings = model.get_embedding(\n",
    "    torch.tensor(train_cat_X_resampled.values, dtype=torch.long).to(device),\n",
    "    torch.tensor(train_num_X_resampled.values, dtype=torch.float).to(device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e619497a1beb5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T16:33:22.476906Z",
     "start_time": "2024-11-30T16:33:22.451095Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_embeddings = model.get_embedding(\n",
    "    torch.tensor(valid_cat_X.values, dtype=torch.long).to(device),\n",
    "    torch.tensor(valid_num_X.values, dtype=torch.float).to(device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b74afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = train_embeddings.cpu().detach().numpy()\n",
    "valid_embeddings = valid_embeddings.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b144bfed44245d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T16:39:25.698222Z",
     "start_time": "2024-11-30T16:33:22.900780Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=300,          # 트리 개수 더욱 증가\n",
    "    max_depth=15,              # 더 깊은 트리 허용\n",
    "    min_samples_leaf=1,        # 리프 노드 최소 샘플 수 더 감소\n",
    "    min_samples_split=3,       # 분할 기준 완화\n",
    "    class_weight={0: 1, 1: 10},  # 사기 클래스에 더 높은 가중치 부여\n",
    "    max_features='sqrt',       \n",
    "    bootstrap=True,\n",
    "    oob_score=True,           # Out-of-bag 점수 확인\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf5756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyun/anaconda3/envs/ai/lib/python3.12/site-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[132890 116832]\n",
      " [   143    215]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.53      0.69    249722\n",
      "         1.0       0.00      0.60      0.00       358\n",
      "\n",
      "    accuracy                           0.53    250080\n",
      "   macro avg       0.50      0.57      0.35    250080\n",
      "weighted avg       1.00      0.53      0.69    250080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_classifier.fit(train_embeddings, train_y_resampled)\n",
    "y_pred = rf_classifier.predict(valid_embeddings)\n",
    "conf_matrix = confusion_matrix(valid_y, y_pred)\n",
    "class_report = classification_report(valid_y, y_pred)\n",
    "print(conf_matrix)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c042c4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest 결과:\n",
      "\n",
      "혼동 행렬:\n",
      "[[249022    700]\n",
      " [   358      0]]\n",
      "\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    249722\n",
      "         1.0       0.00      0.00      0.00       358\n",
      "\n",
      "    accuracy                           1.00    250080\n",
      "   macro avg       0.50      0.50      0.50    250080\n",
      "weighted avg       1.00      1.00      1.00    250080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Isolation Forest를 사용한 이상 탐지\n",
    "# Isolation Forest 파라미터 조정\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=500,          # 트리 개수 증가\n",
    "    max_samples=256,           # 명시적인 샘플 크기 지정\n",
    "    contamination=0.002,       # 실제 사기 비율에 더 가깝게 조정\n",
    "    max_features=0.8,          # 특성 샘플링 비율 지정\n",
    "    bootstrap=True,            # 부트스트랩 샘플링 활성화\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 학습 데이터로 모델 학습\n",
    "iso_forest.fit(train_embeddings)\n",
    "\n",
    "# 예측 수행 (1: 정상, -1: 이상치)\n",
    "iso_pred = iso_forest.predict(valid_embeddings)\n",
    "\n",
    "# -1을 1로, 1을 0으로 변환하여 fraud/non-fraud 레이블로 매핑\n",
    "iso_pred_mapped = np.where(iso_pred == -1, 1, 0)\n",
    "\n",
    "# 성능 평가\n",
    "iso_conf_matrix = confusion_matrix(valid_y, iso_pred_mapped)\n",
    "iso_class_report = classification_report(valid_y, iso_pred_mapped)\n",
    "\n",
    "print(\"Isolation Forest 결과:\")\n",
    "print(\"\\n혼동 행렬:\")\n",
    "print(iso_conf_matrix)\n",
    "print(\"\\n분류 보고서:\")\n",
    "print(iso_class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6371f089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
